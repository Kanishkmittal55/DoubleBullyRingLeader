README – Leader-Election Algorithms Testbench
This repository provides a comprehensive testbench for comparing classic distributed leader-election algorithms (Bully, Ring) with an enhanced “Two-Candidate” or “Double Bully in the Ring” approach. The code demonstrates how to:
1.	Simulate each algorithm under different failure and network-change scenarios.
2.	Measure and compare message overhead and convergence time.
3.	Visualize performance via plots (messages vs. number of nodes, time vs. number of nodes).
Below is a detailed overview of each component, the scenarios tested, and how to run the scripts.
 
1. Purpose of This Testbench
In distributed systems, a leader election algorithm designates exactly one process as the coordinator (or leader). This coordinator is responsible for managing shared resources, coordinating tasks, or otherwise providing a “single point of control” when needed. The classic Bully and Ring algorithms are well-known solutions to this problem, each with its own trade-offs. However, in certain environments—particularly those with low failure rates—the standard methods can be inefficient or overly complex.
Our “Two-Candidate Ring” (Double Bully in the Ring) method proposes maintaining both a coordinator and a pre-appointed backup. If the coordinator fails, the designated checker node simply promotes the backup, thus bypassing lengthy multi-pass elections. This testbench allows you to see how these approaches differ in terms of message overhead and convergence time, and it also illustrates how they behave in real-world scenarios like node failures, new nodes joining, nodes leaving, or network splits.
 
2. What the Testbench Achieves
•	Demonstrates Classic Algorithms
You can see how Bully and Ring behave under various conditions (coordinator failures, node joins, etc.), including literal message-by-message simulations for smaller networks and formula-based approximations for larger ones.
•	Presents the “Two-Candidate Ring” Enhancement
For environments where it’s rare to lose multiple nodes simultaneously, “Two-Candidate Ring” typically provides much lower message overhead and faster leader convergence compared to standard Bully or Ring.
•	Provides Side-by-Side Comparisons
Plots generated by the scripts show how each scenario scales with the number of nodes in terms of total messages exchanged and total convergence time (in seconds).
•	Facilitates Exploration
Users can tweak parameters (like the number of nodes, scenario definitions, or the latency factor) to see how different networks might behave in practice.
 
3. Layout of the Code
The testbench comprises multiple Python classes, each focusing on a specific algorithm or approach:
1.	Bully Algorithm Implementations
o	NormalBullySim (literal recursion) – Enumerates messages for up to ~20 nodes but can become slow for larger n.
o	NormalBully (formula-based) – Uses worst-case O(n²) complexities to estimate overhead for larger node counts quickly.
2.	Ring Algorithm Implementations
o	NormalRingSim (literal ring) – Explicitly simulates all token transmissions in a unidirectional ring; suitable for smaller networks.
o	NormalRingMath (formula-based) – Uses known complexities (~2n or n²) to handle big n values.
3.	Improved “TwoCandidateRingB”
o	A ring variant that stores a designated coordinator and backup.
o	Demonstrates significantly lower overhead (often O(n) or O(1) in small-node-failure cases) when only one node fails at a time.
4.	Scenario Routines
Each algorithm includes five scenarios:
o	Coordinator Failure – The current leader crashes.
o	New Node Arrives – A newcomer with possibly higher ID joins.
o	Small Node Fails – A low-ID process goes down.
o	Node Leaves – The node is removed voluntarily; if it’s the coordinator, a new election triggers.
o	Network Split – The network partitions into two sub-networks, each electing its own leader.
5.	Plotting Functions
For each approach (Bully, Ring, or Two-Candidate), there are plotting helpers that generate:
o	Message Overhead vs. Number of Nodes
o	Convergence Time vs. Number of Nodes
 
4. How to Use and Run
1.	Dependencies
o	Python 3.x
o	matplotlib for plotting
o	(Optionally) numpy in some parts, though not strictly required for the core logic.
2.	Running Each Algorithm’s Main
Each “main_XXX” or “if name == 'main':” block demonstrates usage. For instance, to test the Normal Bully approach:
bash
Copy
python your_script.py
# The code eventually calls main_bully() if it's in that file
Similarly, you can call main_ring() for the Normal Ring tests or main_improved() for the Two-Candidate approach.
3.	Adjusting the Number of Nodes
Look for the list sizes = [10, 20, 30, 40, 50] (or similar) in each main function. You can modify or extend this list to test more node counts. Note that literal simulations (like NormalBullySim or NormalRingSim) may become slow beyond ~20–30 nodes.
4.	Viewing Results
After running the script:
o	Plots will appear in a pop-up window (if using a local Python environment) or inline if using a Jupyter notebook.
o	You’ll see lines for each scenario (A..E) indicating the message overhead or time taken as n grows.
5.	Interpreting the Plots
o	Message Overhead: The total number of message exchanges needed for detection and election.
o	Convergence Time: Computed as message_count × LATENCY_PER_MESSAGE. By default, LATENCY_PER_MESSAGE is set to 0.1 seconds.
 
5. Scenarios in Detail
1.	Coordinator Failure
o	The highest-ID node (coordinator) crashes.
o	Bully triggers many “ELECTION” and “OK” messages (O(n²)).
o	Ring circulates a token around all active nodes (O(n) or 2n).
o	Two-Candidate quickly checks the backup and promotes it (O(n) or fewer).
2.	New Node Arrives
o	If the new node’s ID exceeds the current coordinator’s ID, it may forcibly start a new election.
o	Otherwise, overhead remains minimal.
3.	Small Node Fails
o	If a node other than the coordinator crashes, many algorithms only need partial re-checks.
o	Typically yields low overhead (O(n) or constant overhead in the Two-Candidate approach).
4.	Node Leaves
o	Similar to a node failing, but you might forcibly re-elect if it’s the coordinator.
o	Overheads vary based on the algorithm’s structure.
5.	Network Split
o	The system is partitioned into two or more sub-networks.
o	Each sub-network elects its own coordinator. In the worst case, overhead can be O(n²) for Bully or O(n²) for the Ring.
o	The Two-Candidate approach tries to keep overhead closer to O(n).
 
6. Extensions and Tips
•	Changing the Latency Factor
You can modify LATENCY_PER_MESSAGE to reflect different network speeds. A slower network (e.g., 0.5 seconds per message) amplifies the difference between O(n²) and O(n) approaches.
•	Experimenting with Large n
For big node counts (50+), rely on the formula-based classes (NormalBully, NormalRing, TwoCandidateRingB) or partial-simulation logic. The literal enumerations (NormalBullySim, NormalRingSim) can consume significant time or cause recursion-limit issues.
•	Kubernetes-Like Context
If you run this in a container or orchestrated environment (like Kubernetes), the two-candidate scheme is particularly helpful, because orchestrators often guarantee that at most one node/pod fails at once or else quickly replaces it.
•	Multiple Checkers
In the improved ring, we mostly rely on one “designated checker” to confirm coordinator health. In theory, you could generalize this to multiple watchers or multiple backups, but the overhead and complexity may increase.
 
7. Conclusions
By running these scripts, you’ll get a direct comparison of:
•	Bully Algorithm (traditional approach, can handle multiple simultaneous failures but has high message overhead in many scenarios).
•	Normal Ring (linear structure, simpler concurrency but more vulnerable if the ring link breaks).
•	Improved Two-Candidate Ring (low overhead, fast failover in stable clusters, with a fallback to normal ring if coordinator and backup both fail together).
This testbench thus helps you select or tune a leader-election strategy for your specific distributed system constraints, balancing ease of implementation, overhead, and fault tolerance.
Enjoy experimenting with the code, adjusting parameters, and exploring how each algorithm scales as your distributed system grows. If you have questions about the underlying theory, refer to standard references on Bully and Ring algorithms, and remember that real-world cluster managers often use variants of these protocols internally for master/leader selection.

![image](https://github.com/user-attachments/assets/9605fb09-ce29-4547-bb8d-998e343be3c7)
